{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Embedding,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = [\n",
    "    [1,2,3,4,5,6,7,8,9,10],\n",
    "    [2,3,4,6,7,8,9,0,11,12],\n",
    "    [12,34,56,43,23,12,3,45,67,88],\n",
    "    [34,56,77,50,4,23,2,34,56,78]\n",
    "]\n",
    "\n",
    "targets = [\n",
    "    [2,3,4,5,6,7,8,9,10,0],\n",
    "    [3,4,6,7,8,9,0,11,12,0],\n",
    "    [34,56,43,23,12,3,45,67,88,0],\n",
    "    [56,77,50,4,23,2,34,56,78,0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters(context):\n",
    "    INPUT_DIM = max([max(ctx) for ctx in context])+1\n",
    "    OUTPUT_DIM = 8\n",
    "    INPUT_LENGTH = len(context[0])\n",
    "    EPOCHS = 100\n",
    "    VERBOSE = 1\n",
    "    LOSS = 'categorical_crossentropy'\n",
    "    ACTIVATION = 'softmax'\n",
    "    OPTIMIZER = 'adam'\n",
    "    MATRIX = ['accuracy']\n",
    "    return (INPUT_DIM, OUTPUT_DIM, INPUT_LENGTH, EPOCHS, VERBOSE, LOSS, ACTIVATION, OPTIMIZER, MATRIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM, OUTPUT_DIM, INPUT_LENGTH, EPOCHS, VERBOSE, LOSS, ACTIVATION, OPTIMIZER, MATRIX = parameters(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "callback_list = [tf.keras.callbacks.ModelCheckpoint(filepath=\"embeddings.h5\", monitor = MATRIX[0], \n",
    "                                                            save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 10, 8)             712       \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                810       \n",
      "=================================================================\n",
      "Total params: 1,522\n",
      "Trainable params: 1,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(input_dim=INPUT_DIM, output_dim=OUTPUT_DIM, input_length=INPUT_LENGTH)\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(INPUT_LENGTH, activation = ACTIVATION))\n",
    "model.compile(optimizer = OPTIMIZER, loss=LOSS, metrics = MATRIX)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 499.8993 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 499.6583 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 499.4215 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 499.1911 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 498.9657 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 498.7441 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 498.5256 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 498.3100 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 498.0967 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 497.8854 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 497.6754 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 497.4663 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 497.2577 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 497.0490 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 496.8401 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 496.6305 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 496.4199 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 496.2081 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 495.9947 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 495.7796 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 495.5625 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 495.3432 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 495.1215 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 494.8971 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 494.6700 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 494.4398 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 494.2066 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 493.9701 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 493.7302 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 493.4867 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 493.2396 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 492.9887 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 492.7339 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 492.4752 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 492.2123 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 491.9454 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 491.6742 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 491.3987 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 491.1188 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 490.8345 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 490.5457 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 490.2526 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 489.9550 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 489.6531 - accuracy: 0.2500\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 489.3469 - accuracy: 0.2500\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 489.0364 - accuracy: 0.2500\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 488.7218 - accuracy: 0.2500\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 488.4030 - accuracy: 0.2500\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 488.0804 - accuracy: 0.2500\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 487.7540 - accuracy: 0.2500\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 487.4239 - accuracy: 0.2500\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 487.0904 - accuracy: 0.2500\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 486.7534 - accuracy: 0.2500\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 486.4133 - accuracy: 0.2500\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 486.0702 - accuracy: 0.2500\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 485.7243 - accuracy: 0.2500\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 485.3759 - accuracy: 0.2500\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 485.0249 - accuracy: 0.2500\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 484.6719 - accuracy: 0.2500\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 484.3168 - accuracy: 0.2500\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 483.9600 - accuracy: 0.2500\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 483.6016 - accuracy: 0.2500\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 483.2419 - accuracy: 0.2500\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 482.8812 - accuracy: 0.2500\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 482.5196 - accuracy: 0.2500\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 482.1574 - accuracy: 0.2500\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 481.7947 - accuracy: 0.2500\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 481.4320 - accuracy: 0.2500\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 481.0693 - accuracy: 0.2500\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 480.7068 - accuracy: 0.2500\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 480.3449 - accuracy: 0.2500\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 479.9838 - accuracy: 0.2500\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 479.6236 - accuracy: 0.2500\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 479.2646 - accuracy: 0.2500\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 478.9070 - accuracy: 0.2500\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 478.5510 - accuracy: 0.2500\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 478.1967 - accuracy: 0.2500\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 477.8445 - accuracy: 0.2500\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 477.4944 - accuracy: 0.2500\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 477.1467 - accuracy: 0.2500\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 476.8015 - accuracy: 0.2500\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 476.4589 - accuracy: 0.2500\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 476.1192 - accuracy: 0.2500\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 475.7825 - accuracy: 0.2500\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 475.4489 - accuracy: 0.2500\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 475.1185 - accuracy: 0.2500\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 474.7915 - accuracy: 0.2500\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 474.4680 - accuracy: 0.2500\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 474.1480 - accuracy: 0.2500\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 473.8318 - accuracy: 0.2500\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 473.5195 - accuracy: 0.2500\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 473.2108 - accuracy: 0.2500\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 472.9063 - accuracy: 0.2500\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 472.6057 - accuracy: 0.2500\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 472.3091 - accuracy: 0.2500\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 472.0168 - accuracy: 0.2500\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 471.7286 - accuracy: 0.2500\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 471.4447 - accuracy: 0.2500\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 471.1649 - accuracy: 0.2500\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 470.8896 - accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(context, targets, epochs = EPOCHS, verbose=VERBOSE, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = embedding_layer.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13586375,  0.11028997, -0.12732497, -0.15861087, -0.12188546,\n",
       "        0.00272284, -0.10573886,  0.14364102], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = []\n",
    "targ = []\n",
    "for ctx in context:\n",
    "    for cx in ctx:\n",
    "        cont.append(cx)\n",
    "        targ.append(np.argmax(pred[cx]))\n",
    "df = pd.DataFrame({'Word':cont, 'Next Predicted Word':targ})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Next Predicted Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>77</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word  Next Predicted Word\n",
       "0      1                    7\n",
       "1      2                    5\n",
       "2      3                    4\n",
       "3      4                    3\n",
       "4      5                    7\n",
       "5      6                    0\n",
       "6      7                    2\n",
       "7      8                    7\n",
       "8      9                    0\n",
       "9     10                    7\n",
       "10     2                    5\n",
       "11     3                    4\n",
       "12     4                    3\n",
       "13     6                    0\n",
       "14     7                    2\n",
       "15     8                    7\n",
       "16     9                    0\n",
       "17     0                    7\n",
       "18    11                    3\n",
       "19    12                    1\n",
       "20    12                    1\n",
       "21    34                    7\n",
       "22    56                    2\n",
       "23    43                    6\n",
       "24    23                    7\n",
       "25    12                    1\n",
       "26     3                    4\n",
       "27    45                    0\n",
       "28    67                    3\n",
       "29    88                    1\n",
       "30    34                    7\n",
       "31    56                    2\n",
       "32    77                    4\n",
       "33    50                    0\n",
       "34     4                    3\n",
       "35    23                    7\n",
       "36     2                    5\n",
       "37    34                    7\n",
       "38    56                    2\n",
       "39    78                    1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "8hb5s",
   "launcher_item_id": "5NrJ6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
